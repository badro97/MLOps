{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# ì¶”ê°€ ì„ í˜• ëª¨ë¸ import\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Iris ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/09 18:59:44 INFO mlflow.tracking.fluent: Experiment with name 'Modle Compare' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/148841437545004186', creation_time=1741514384397, experiment_id='148841437545004186', last_update_time=1741514384397, lifecycle_stage='active', name='Modle Compare', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "## create a new MLflow experiment\n",
    "mlflow.set_experiment(\"Modle Compare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression ì •í™•ë„: 1.0000\n",
      "ğŸƒ View run logistic_regression at: http://127.0.0.1:5000/#/experiments/148841437545004186/runs/10b5cafb0228480f86803989c3dd8966\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/148841437545004186\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. LogisticRegression ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "with mlflow.start_run(run_name=\"logistic_regression\"):\n",
    "    lr_model = LogisticRegression(max_iter=200)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # ì˜ˆì¸¡\n",
    "    y_pred = lr_model.predict(X_test)\n",
    "    \n",
    "    # ì •í™•ë„ ê³„ì‚°\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"LogisticRegression ì •í™•ë„: {accuracy:.4f}\")\n",
    "    \n",
    "    # MLflowì— ë©”íŠ¸ë¦­ ê¸°ë¡\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"max_iter\", 200)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    # ëª¨ë¸ ì„œëª… ì¶”ë¡  ë° ëª¨ë¸ ì €ì¥\n",
    "    signature = infer_signature(X_test, y_pred)\n",
    "    LogisticRegression_info = mlflow.sklearn.log_model(lr_model, \"logistic_regression_model\", signature=signature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression ì •í™•ë„: 1.0000\n",
      "LinearRegression MSE: 0.0371\n",
      "LinearRegression RÂ²: 0.9469\n",
      "ğŸƒ View run linear_regression at: http://127.0.0.1:5000/#/experiments/148841437545004186/runs/8a20f99dd2f24e4e910f73bed42e8353\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/148841437545004186\n"
     ]
    }
   ],
   "source": [
    "# 2. LinearRegression ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "with mlflow.start_run(run_name=\"linear_regression\"):\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X_train, y_train)\n",
    "    \n",
    "    # ì˜ˆì¸¡\n",
    "    y_pred_linear = linear_model.predict(X_test)\n",
    "    # ë°˜ì˜¬ë¦¼í•˜ì—¬ ë¶„ë¥˜ ê²°ê³¼ë¡œ ë³€í™˜\n",
    "    y_pred_linear_rounded = np.round(y_pred_linear).astype(int)\n",
    "    # ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ê°’ ì²˜ë¦¬\n",
    "    y_pred_linear_rounded = np.clip(y_pred_linear_rounded, 0, 2)\n",
    "    \n",
    "    # í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "    accuracy_linear = accuracy_score(y_test, y_pred_linear_rounded)\n",
    "    mse = mean_squared_error(y_test, y_pred_linear)\n",
    "    r2 = r2_score(y_test, y_pred_linear)\n",
    "    \n",
    "    print(f\"LinearRegression ì •í™•ë„: {accuracy_linear:.4f}\")\n",
    "    print(f\"LinearRegression MSE: {mse:.4f}\")\n",
    "    print(f\"LinearRegression RÂ²: {r2:.4f}\")\n",
    "    \n",
    "    # MLflowì— ë©”íŠ¸ë¦­ ê¸°ë¡\n",
    "    mlflow.log_param(\"model_type\", \"LinearRegression\")\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_linear)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    \n",
    "    # ëª¨ë¸ ì„œëª… ì¶”ë¡  ë° ëª¨ë¸ ì €ì¥\n",
    "    signature = infer_signature(X_test, y_pred_linear)\n",
    "    LinearRegression_info = mlflow.sklearn.log_model(linear_model, \"linear_regression_model\", signature=signature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge ì •í™•ë„: 1.0000\n",
      "Ridge MSE: 0.0391\n",
      "Ridge RÂ²: 0.9441\n",
      "ğŸƒ View run ridge_regression at: http://127.0.0.1:5000/#/experiments/148841437545004186/runs/bfe31efc0d4042d78860104517185a57\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/148841437545004186\n"
     ]
    }
   ],
   "source": [
    "# 3. Ridge ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "with mlflow.start_run(run_name=\"ridge_regression\"):\n",
    "    ridge_model = Ridge(alpha=1.0)\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "    \n",
    "    # ì˜ˆì¸¡\n",
    "    y_pred_ridge = ridge_model.predict(X_test)\n",
    "    y_pred_ridge_rounded = np.round(y_pred_ridge).astype(int)\n",
    "    y_pred_ridge_rounded = np.clip(y_pred_ridge_rounded, 0, 2)\n",
    "    \n",
    "    # í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "    accuracy_ridge = accuracy_score(y_test, y_pred_ridge_rounded)\n",
    "    mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "    r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "    \n",
    "    print(f\"Ridge ì •í™•ë„: {accuracy_ridge:.4f}\")\n",
    "    print(f\"Ridge MSE: {mse_ridge:.4f}\")\n",
    "    print(f\"Ridge RÂ²: {r2_ridge:.4f}\")\n",
    "    \n",
    "    # MLflowì— ë©”íŠ¸ë¦­ ê¸°ë¡\n",
    "    mlflow.log_param(\"model_type\", \"Ridge\")\n",
    "    mlflow.log_param(\"alpha\", 1.0)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_ridge)\n",
    "    mlflow.log_metric(\"mse\", mse_ridge)\n",
    "    mlflow.log_metric(\"r2\", r2_ridge)\n",
    "    \n",
    "    # ëª¨ë¸ ì„œëª… ì¶”ë¡  ë° ëª¨ë¸ ì €ì¥\n",
    "    signature = infer_signature(X_test, y_pred_ridge)\n",
    "    Ridge_info = mlflow.sklearn.log_model(ridge_model, \"ridge_model\", signature=signature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso ì •í™•ë„: 0.9667\n",
      "Lasso MSE: 0.0668\n",
      "Lasso RÂ²: 0.9045\n",
      "ğŸƒ View run lasso_regression at: http://127.0.0.1:5000/#/experiments/148841437545004186/runs/71a6c3b392fb4fe0ad1fdf91cf7f2ed6\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/148841437545004186\n"
     ]
    }
   ],
   "source": [
    "# 4. Lasso ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "with mlflow.start_run(run_name=\"lasso_regression\"):\n",
    "    lasso_model = Lasso(alpha=0.1)\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    \n",
    "    # ì˜ˆì¸¡\n",
    "    y_pred_lasso = lasso_model.predict(X_test)\n",
    "    y_pred_lasso_rounded = np.round(y_pred_lasso).astype(int)\n",
    "    y_pred_lasso_rounded = np.clip(y_pred_lasso_rounded, 0, 2)\n",
    "    \n",
    "    # í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "    accuracy_lasso = accuracy_score(y_test, y_pred_lasso_rounded)\n",
    "    mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "    r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "    \n",
    "    print(f\"Lasso ì •í™•ë„: {accuracy_lasso:.4f}\")\n",
    "    print(f\"Lasso MSE: {mse_lasso:.4f}\")\n",
    "    print(f\"Lasso RÂ²: {r2_lasso:.4f}\")\n",
    "    \n",
    "    # MLflowì— ë©”íŠ¸ë¦­ ê¸°ë¡\n",
    "    mlflow.log_param(\"model_type\", \"Lasso\")\n",
    "    mlflow.log_param(\"alpha\", 0.1)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_lasso)\n",
    "    mlflow.log_metric(\"mse\", mse_lasso)\n",
    "    mlflow.log_metric(\"r2\", r2_lasso)\n",
    "    \n",
    "    # ëª¨ë¸ ì„œëª… ì¶”ë¡  ë° ëª¨ë¸ ì €ì¥\n",
    "    signature = infer_signature(X_test, y_pred_lasso)\n",
    "    Lasso_info = mlflow.sklearn.log_model(lasso_model, \"lasso_model\", signature=signature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ëª¨ë¸ ì •í™•ë„ ë¹„êµ:\n",
      "                Model  Accuracy\n",
      "0  LogisticRegression  1.000000\n",
      "1    LinearRegression  1.000000\n",
      "2               Ridge  1.000000\n",
      "3               Lasso  0.966667\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\n",
    "models = [\"LogisticRegression\", \"LinearRegression\", \"Ridge\", \"Lasso\"]\n",
    "accuracies = [accuracy, accuracy_linear, accuracy_ridge, accuracy_lasso]\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Model\": models,\n",
    "    \"Accuracy\": accuracies\n",
    "})\n",
    "print(\"\\nëª¨ë¸ ì •í™•ë„ ë¹„êµ:\")\n",
    "print(comparison_df.sort_values(\"Accuracy\", ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
